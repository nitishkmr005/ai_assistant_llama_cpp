# Chat Assistant Project Requirements

## Core Requirements
1. Flask-based web application
2. Integration with llama-cpp for loading GGUF format LLM models
3. UI matching the provided design screenshot

## UI Components
1. Model selector dropdown (top-left)
2. Temperature slider (top-right)
3. Chat message display area (center)
4. Message input box (bottom)
5. Send button (bottom-right)

## Technical Specifications
1. Backend: Flask
2. LLM Integration: llama-cpp-python
3. Frontend: HTML, CSS, JavaScript
4. Real-time chat updates
5. Model parameter controls 